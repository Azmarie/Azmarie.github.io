{"componentChunkName":"component---src-templates-paper-review-tsx","path":"/paper-review/Rendering2/","result":{"data":{"site":{"siteMetadata":{"title":"Azmarie Wang","author":"Azmarie Wang"}},"markdownRemark":{"id":"6b4d82ef-c073-51ad-9c70-a26a8feba98a","excerpt":"Main Contribution The research problem in this paper is image rendering, designed to accommodate for subsurface scattering in translucent materials such as…","html":"<h2 id=\"main-contribution\" style=\"position:relative;\"><a href=\"#main-contribution\" aria-label=\"main contribution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Main Contribution</h2>\n<p>The research problem in this paper is image rendering, designed to accommodate for subsurface scattering in translucent materials such as liquids and human skin. Subsurface scattering refers to the phenomena where light enters the object, it scatters and propagates inside the material, and then either gets absorbed or leaves the object at a separate location of lower intensity. </p>\n<p>The main contribution includes a practical model of BSSRDF, which efficiently renders a realistic simulation of the object capturing the translucency effect, and its mathematical foundation. This research problem is important because most of the material is translucent to some degree in reality. This is especially useful for the development of realistic CGI and medical physics research.</p>\n<h2 id=\"method\" style=\"position:relative;\"><a href=\"#method\" aria-label=\"method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Method</h2>\n<p>Compared to the simplified BRDF model where light enters and leaves at the same surface point, the authors utilize the BSSRDF model accommodating phenomena like subsurface scattering. BSSRDF stands for the bidirectional scattering-surface reflectance distribution function, which describes how light enters an object, scatters around it, and then leaves the surface at a different location. In technical terms, it illustrates the relationship between outgoing radiance and the incident flux in light propagation with reduced intensity. Building on the theory of BSSRDF, the authors constructed this model with two parts - the diffusion approximation term and the single scattering term. </p>\n<p>First, the diffusion approximation is based on the isotropic light distribution in highly scattering media, which in simple terms, means roughly the same light distribution measured in different directions. </p>\n<p>As mentioned earlier, the surface scattering transports light from one point to another. Intuitively, the diffusion term is approximated by the distance of these two points and the Fresnel terms of the incoming and the outgoing light vectors. The dipole is the method of estimating the reflectance from two point sources, which is often a solution in diffusion problems. Here, the authors constructed these two point sources on the opposite side of the surface, with positive and negative contributions individually. In this step, the authors <b>assume a locally flat and semi-infinite homogeneous media</b>. However, in reality, this could hardly be the case. Hence, I think this could be one of the limitations of this method. </p>\n<p>Secondly, the single scattering term extends from a previous model for BRDF. The outgoing radiance after a single scattering is calculated by integrating the incident radiance along the refracted outgoing ray, which accounts for each reflection on the surface. Taking two parts together, the complete model is a sum of the diffusion approximation and the single scattering term.</p>\n<h2 id=\"whats-good-and-whats-not-so-good\" style=\"position:relative;\"><a href=\"#whats-good-and-whats-not-so-good\" aria-label=\"whats good and whats not so good permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What’s good and what’s not so good?</h2>\n<p>This model exceeded the state-of-art method by its great results and efficiency. The authors argued that this outperformed the BRDF models since it produces a soft-looking surface that is more realistic and closer to human eye perception for the translucent materials. It also exceeds the brute force path tracing method in speed and efficiency, though could be less performant than a BRDF due to its computational complexity. In my opinion, this paper is novel in proposing a practical model to formulate the problem of subsurface scattering, which paved the foundation for future work and spike in CGI in the movie industry. One limitation of the paper, as mentioned earlier, is the idealistic assumptions made about the scattering media, in reality, which may not be the case. </p>\n<h2 id=\"future-work\" style=\"position:relative;\"><a href=\"#future-work\" aria-label=\"future work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Future Work</h2>\n<p>In my research around this paper, I found an extension by the author in 2005 [4] on multipole diffusion approximation for better results. Some other extensions were various efforts made in handcrafting solutions for a specific texture such as hair shading [1], rainbows in nature[2], and fur[3]. The results from the above papers are stunning and many of them are mature enough to be applied in the industry. </p>\n<p>This, on the other hand, makes me think about the <b>trade-off between using a traditional handcrafted method like this one and a deep learning method in computer vision and graphic tasks</b>. Many deep learning networks that we consider as standard these days, such as CNN or GAN, can often be constructed as a general-purpose or multi-tasking architecture, which achieve generally good results on images from different domains. </p>\n<p>However, the <b>generalizability of neural networks</b> is not guaranteed on edge or real-world complex cases, for example, in the areas the extensions of this work have addressed - complex texture like fur, hair, rainbows. Another potential problem with neural networks in image rendering is the flexibility to deal with an artifact, as we couldn’t fiddle with the networks directly case by case.</p>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>[1] Sadeghi, I., Pritchett, H., Jensen, H. W., &#x26; Tamstorf, R. (2010). An artist friendly hair shading system. ACM Transactions on Graphics (TOG), 29(4), 1-10.</p>\n<p>[2] Sadeghi, I., Munoz, A., Laven, P., Jarosz, W., Seron, F., Gutierrez, D., &#x26; Jensen, H. W. (2012). Physically-based simulation of rainbows. ACM Transactions on Graphics (TOG), 31(1), 1-12.</p>\n<p>[3] Yan, L. Q., Sun, W., Jensen, H. W., &#x26; Ramamoorthi, R. (2017). A BSSRDF model for efficient rendering of fur with global illumination. ACM Transactions on Graphics (TOG), 36(6), 1-13.</p>\n<p>[4] Donner, C., &#x26; Jensen, H. W. (2005). Light diffusion in multi-layered translucent materials. ACM Transactions on Graphics (ToG), 24(3), 1032-1039.</p>","fields":{"slug":"/Rendering2/"},"frontmatter":{"shortDate":"October 11, 2020","title":"A Practical Model for Subsurface Light Transport","categories":["Rendering"],"summaryType":"Paper Review","paperPDFLink":"https://graphics.stanford.edu/papers/bssrdf/bssrdf.pdf","projectLink":null,"projectTitle":null,"reference":"Jensen, Henrik Wann, Stephen R. Marschner, Marc Levoy, and Pat Hanrahan. \"A practical model for subsurface light transport.\" In Proceedings of the 28th annual conference on Computer graphics and interactive techniques, pp. 511-518. 2001.","published":true,"cover":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAABVh0NYmbAf//EABcQAQEBAQAAAAAAAAAAAAAAAAEDAgD/2gAIAQEAAQUC3O2UKOoTsZ2GwlM13//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EAB0QAAIBBAMAAAAAAAAAAAAAAAERAAIQEjEhQXH/2gAIAQEABj8CZYHPc2fHDlluKoMQEUB2/8QAGRABAQEBAQEAAAAAAAAAAAAAAREAMUFR/9oACAEBAAE/IelcKwezSA1k9fp3E5rmvmg9axxJIaOF3//aAAwDAQACAAMAAAAQsM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAEBAAMBAQAAAAAAAAAAAAABEQAhMUGh/9oACAEBAAE/EKEtW8Oy3ffmNHEw2QkDpy7GStjBPc1ZxBqnuTDvg0XrkXfmf//Z","aspectRatio":1.6304347826086956,"src":"/static/846e1ec18e9249232c54fdf438579525/47498/teaser-optimized.jpg","srcSet":"/static/846e1ec18e9249232c54fdf438579525/9dc27/teaser-optimized.jpg 300w,\n/static/846e1ec18e9249232c54fdf438579525/4fe8c/teaser-optimized.jpg 600w,\n/static/846e1ec18e9249232c54fdf438579525/47498/teaser-optimized.jpg 1200w,\n/static/846e1ec18e9249232c54fdf438579525/52258/teaser-optimized.jpg 1800w,\n/static/846e1ec18e9249232c54fdf438579525/4e1b9/teaser-optimized.jpg 1844w","sizes":"(max-width: 1200px) 100vw, 1200px"}}}}}},"pageContext":{"slug":"/Rendering2/"}},"staticQueryHashes":["63159454"]}