{"componentChunkName":"component---src-templates-paper-review-tsx","path":"/paper-review/Rendering1/","result":{"data":{"site":{"siteMetadata":{"title":"Azmarie Wang","author":"Azmarie Wang"}},"markdownRemark":{"id":"e8520827-281f-509d-9454-ce66d23d3180","excerpt":"Main Contribution The research problem in this paper is interactive image reconstruction/ rendering. This problem is relevant in the gaming industry and…","html":"<h2 id=\"main-contribution\" style=\"position:relative;\"><a href=\"#main-contribution\" aria-label=\"main contribution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Main Contribution</h2>\n<p>The research problem in this paper is interactive image reconstruction/ rendering. This problem is relevant in the gaming industry and especially in AR/ VR applications enabling real-time experiences. Motivated by the success of image restoration using neural networks in recent years, the authors aimed to target the ray tracing denoising problem as reconstructing image sequences with the help of deep neural networks. </p>\n<p>The main contributions include the proposal of using novel recurrent connections in deep autoencoder networks for temporal stability, which is end-to-end trainable thus can automatically learn relationships based on auxiliary per-pixel input channels. Noteworthy, the network achieved a good execution speed with high-quality results from extremely low sampling frames.   </p>\n<h2 id=\"method\" style=\"position:relative;\"><a href=\"#method\" aria-label=\"method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Method</h2>\n<p>The proposed architecture is a recurrent autoencoder with skip connection every second layer, trained end to end in a supervised manner with paired data. In the paper, the authors refer to the autoencoder as denoising autoencoders. Autoencoders are known to be effective in learning to reconstruct the inputs from a minimal latent representation obtained in the bottleneck. The noise is often random and can be averaged out, so it is regarded as non-essential information and won’t be included in the latent representation. </p>\n<p>Moreover, I think the usage of RNN is also easily justifiable intuitively. The past frames can provide useful information in constructing the current frame through the feedback loop, thus the recurrent connections are a good structure for temporal coherence. The authors made it clear that they are focusing on solving the reconstruction task with an extremely low amount of sampling frames. Thus, using the recurrent structure can obtain illumination information from its sparse sampling point. The temporal features are learnt at multiple scales through recurrent blocks. The architecture is fully convolutional, so it is trainable in small fixed resolution and much faster than training on the full resolution (such as a CNN with skip connection network). </p>\n<p>Further, the network is end-to-end trainable and put auxiliary inputs automatically into use to disambiguate the colour data. The tradeoff of using an RNN is between the <b>temporal coherency and the expensive hierarchy of recurrent blocks</b>. Since this paper focuses on rendering at an interactive rate with low sample counts, it is not production-quality ready and the performance suffers from low sampling. Besides, neural networks tend to produce what is seen frequently more prominently, thus it may produce poor quality for a complex scene and rare objects. The authors mentioned that they choose to not consider the depth of field and motion blur, which limited the application to gaming and other virtual experiences. </p>\n<h2 id=\"whats-good-and-whats-not-so-good\" style=\"position:relative;\"><a href=\"#whats-good-and-whats-not-so-good\" aria-label=\"whats good and whats not so good permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What’s good and what’s not so good?</h2>\n<p>In the experiments, the authors showcased examples where the inputs were highly noisy, and the network generated good quality outputs. However, it would be good to know <b>if the trained network can fit inputs with multiple intensity of noise</b>, such as mildly noisy and extremely noisy. I think the authors have yet to explore the spatial property of the objects in the video, adding spatial information to be jointly optimized with the temporal information could be a possible extension while keeping the low sample count. </p>\n<p>Overall, this paper is a successful example of using deep learning techniques in image rendering. It seems that deep learning is not only great for image restoration tasks but also is readily employable for image sequences for light transport reconstruction. It set good examples for future deep learning based ray tracing denoisers, where different types of kernels are learnt to substitute for the hand crafted kernels. </p>","fields":{"slug":"/Rendering1/"},"frontmatter":{"shortDate":"October 11, 2020","title":"Interactive Reconstruction of Monte Carlo Image Sequences using a Recurrent Denoising Autoencoder","categories":["Rendering"],"summaryType":"Paper Review","paperPDFLink":"https://research.nvidia.com/sites/default/files/publications/dnn_denoise_author.pdf","projectLink":null,"projectTitle":null,"reference":"Chaitanya, Chakravarty R. Alla, Anton S. Kaplanyan, Christoph Schied, Marco Salvi, Aaron Lefohn, Derek Nowrouzezahrai, and Timo Aila. \"Interactive reconstruction of Monte Carlo image sequences using a recurrent denoising autoencoder.\" ACM Transactions on Graphics (TOG) 36, no. 4 (2017): 1-12.","published":true,"cover":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAID/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAcbJQP/EABkQAAIDAQAAAAAAAAAAAAAAAAACAQMRE//aAAgBAQABBQJaGOLE0zv/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwFX/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQIBAT8BR//EABgQAAMBAQAAAAAAAAAAAAAAAAABAiIy/9oACAEBAAY/Anmh5o5o/8QAHBABAAIBBQAAAAAAAAAAAAAAAQARITFBUWFx/9oACAEBAAE/ISAaNc7se6ZfY+yy8T//2gAMAwEAAgADAAAAEPff/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQMBAT8Qqn//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPxCIf//EABoQAQADAQEBAAAAAAAAAAAAAAEAESExYZH/2gAIAQEAAT8QowSHV6e8iUKHFe6w3kWaYW1X9n//2Q==","aspectRatio":2.6315789473684212,"src":"/static/e0fe8132cfd57e10b7d986dad2b0bcab/47498/teaser-optimized.jpg","srcSet":"/static/e0fe8132cfd57e10b7d986dad2b0bcab/9dc27/teaser-optimized.jpg 300w,\n/static/e0fe8132cfd57e10b7d986dad2b0bcab/4fe8c/teaser-optimized.jpg 600w,\n/static/e0fe8132cfd57e10b7d986dad2b0bcab/47498/teaser-optimized.jpg 1200w,\n/static/e0fe8132cfd57e10b7d986dad2b0bcab/52258/teaser-optimized.jpg 1800w,\n/static/e0fe8132cfd57e10b7d986dad2b0bcab/50587/teaser-optimized.jpg 2400w,\n/static/e0fe8132cfd57e10b7d986dad2b0bcab/4ef0a/teaser-optimized.jpg 2780w","sizes":"(max-width: 1200px) 100vw, 1200px"}}}}}},"pageContext":{"slug":"/Rendering1/"}},"staticQueryHashes":["63159454"]}