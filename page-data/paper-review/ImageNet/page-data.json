{"componentChunkName":"component---src-templates-paper-review-tsx","path":"/paper-review/ImageNet/","result":{"data":{"site":{"siteMetadata":{"title":"Azmarie Wang","author":"Azmarie Wang"}},"markdownRemark":{"id":"68e1d4d7-8e6a-540c-b569-5e3a82a38dc6","excerpt":"What’s ImageNet? Inspired by the explosion of data, ImageNet proposed to target an ambitious research problem - how to harness the power of vast quantities of…","html":"<h2 id=\"whats-imagenet\" style=\"position:relative;\"><a href=\"#whats-imagenet\" aria-label=\"whats imagenet permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What’s ImageNet?</h2>\n<p>Inspired by the explosion of data, ImageNet proposed to target an ambitious research problem - how to harness the power of vast quantities of image data and organize them in such a way that’s beneficial to a variety of research problems. The main contribution in the paper is the introduction of a large-scale, highly-diverse, and highly-accurate database built on the hierarchical structure of WordNet called <code class=\"language-text\">ImageNet</code>.</p>\n<h2 id=\"method\" style=\"position:relative;\"><a href=\"#method\" aria-label=\"method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Method</h2>\n<p>Constructing an accurate large-scale database is no easy task. In ImageNet, the data was collected by querying several image search engines per synset and then verified by global users leveraging the services of <a href=\"https://www.mturk.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Amazon Mechanical Turk</a> to reach a predetermined confidence score threshold. The paper advanced the state-of-art dataset by its large scale, high accuracy, and large diversity, and also its semantic hierarchy based on WordNet. One limitation of the ImageNet could be its choice of assigning only a single label to each image, it’s not optimal when there are more than one clear objects in the image.</p>\n<h2 id=\"whats-good\" style=\"position:relative;\"><a href=\"#whats-good\" aria-label=\"whats good permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What’s good?</h2>\n<p>What I found as inherently novel about ImageNet is its <b>focus and belief in data</b> - a fair representation of the problem space with data is important and can be beneficial to computer vision tasks regardless of the algorithm and models. In hindsight, ImageNet has been proven to be a supreme source of training data and benchmark datasets. </p>\n<h2 id=\"future-work\" style=\"position:relative;\"><a href=\"#future-work\" aria-label=\"future work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Future Work</h2>\n<p>ImageNet and ImageNet Challenge inspired a stream of work in the neural networks which generated groundbreaking results, to the point where transfer learning via pre training on ImageNet is widely used as a standard procedure before fine-tuning on another dataset. One possible extension into the computer graphic tasks will be to extend the ImageNet dataset into 3D, including depth information for a 2D scene. Even though a 3D dataset is even more costly to obtain, it could benefit 3D scene understanding and robotic tasks greatly. </p>","fields":{"slug":"/ImageNet/"},"frontmatter":{"shortDate":"September 20, 2020","title":"ImageNet: a Large-Scale Hierarchical Image Database","categories":["Dataset"],"summaryType":"Paper Review","paperPDFLink":"https://www.researchgate.net/profile/Li_Jia_Li/publication/221361415_ImageNet_a_Large-Scale_Hierarchical_Image_Database/links/00b495388120dbc339000000/ImageNet-a-Large-Scale-Hierarchical-Image-Database.pdf","projectLink":"http://www.image-net.org/","projectTitle":"ImageNet","reference":"Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. \"Imagenet: A large-scale hierarchical image database.\" In 2009 IEEE conference on computer vision and pattern recognition, pp. 248-255. Ieee, 2009.","published":true,"cover":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAv/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAABlRVrNSPD/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAIBAxAREv/aAAgBAQABBQJ2aDqwlNi5/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAgEFAAAAAAAAAAAAAAAAARAAESIycaH/2gAIAQEABj8CsFZjxDT/AP/EABsQAAEEAwAAAAAAAAAAAAAAABEAATFxECFB/9oACAEBAAE/IRdhwV3QQRt5CjXn/9oADAMBAAIAAwAAABDwP//EABURAQEAAAAAAAAAAAAAAAAAAAEA/9oACAEDAQE/EFgL/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARIf/aAAgBAgEBPxAeWt//xAAbEAEAAwEAAwAAAAAAAAAAAAABABEhMRBRof/aAAgBAQABPxBYiG9HpNUqzMe/Zu76WUX4gdI9n//Z","aspectRatio":2.3255813953488373,"src":"/static/d14b99e2368fa01e461f0aa7fe00f33e/47498/teaser-optimized.jpg","srcSet":"/static/d14b99e2368fa01e461f0aa7fe00f33e/9dc27/teaser-optimized.jpg 300w,\n/static/d14b99e2368fa01e461f0aa7fe00f33e/4fe8c/teaser-optimized.jpg 600w,\n/static/d14b99e2368fa01e461f0aa7fe00f33e/47498/teaser-optimized.jpg 1200w,\n/static/d14b99e2368fa01e461f0aa7fe00f33e/f2e3f/teaser-optimized.jpg 1400w","sizes":"(max-width: 1200px) 100vw, 1200px"}}}}}},"pageContext":{"slug":"/ImageNet/"}},"staticQueryHashes":["63159454"]}